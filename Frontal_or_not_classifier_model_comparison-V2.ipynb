{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ad4130",
   "metadata": {},
   "source": [
    "# import the necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf9142",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6950ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112c287",
   "metadata": {},
   "source": [
    "# Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aaaa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38fd29",
   "metadata": {},
   "source": [
    "# GPU Problem: LÃ¶sung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6d7ff",
   "metadata": {},
   "source": [
    "# Set Some Parameters GPU and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ba648",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1504da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b8988",
   "metadata": {},
   "source": [
    "# Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c80b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "\n",
    "data_path='datasets2'\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
    "\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e231895",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.load_img(\"datasets2/Training/Face_Not_Frontal/Tr-Face_Not_Frontal (33).jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe287fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(\"datasets2/Training/Face_Not_Frontal/Tr-Face_Not_Frontal (33).jpg\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d2647",
   "metadata": {},
   "source": [
    "# Set Some Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Dataset information\n",
    "\n",
    "# Test dataset is set explicitly, because the amount of data is very small\n",
    "#train_aug_image_folder = os.path.join('datasets2', 'Training_aug_images')\n",
    "train_image_folder = os.path.join('datasets2', 'Training')\n",
    "test_image_folder = os.path.join('datasets2', 'Testing')\n",
    "img_height, img_width = 250, 250  # size of images\n",
    "num_classes = 2  # me - not_me\n",
    "\n",
    "# Training settings\n",
    "validation_ratio = 0.15  # 15% for the validation\n",
    "batch_size = 16\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets2/Training/'\n",
    "valid_path = 'datasets2/Validation/'\n",
    "test_path = 'datasets2/Testing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9444b4c6",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab79f7d",
   "metadata": {},
   "source": [
    "# Read datasets from folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_path,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_batches = test_datagen.flow_from_directory(\n",
    "        valid_path,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "test_batches = test_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        test_path,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=10,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1425932",
   "metadata": {},
   "source": [
    "# Build and train the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408fec6",
   "metadata": {},
   "source": [
    "# Model Building: Create a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell:2CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=(img_height, img_width,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Conv2D(filters=200,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "\n",
    "model.add(Dense(50,activation='relu'))\n",
    "#Dense layer of 64 neurons\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "#output layer:The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a59c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de8adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell 3CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',input_shape=(img_height, img_width,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "#1st CNN layer\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "#2nd CNN layer\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "#3rd CNN layer\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from 3rd CNN layer\n",
    "\n",
    "model.add(Dense(units=2,activation='sigmoid'))\n",
    "#output layer: The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60277ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622f532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell 4CNN\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",input_shape=(img_height, img_width,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(5,5),padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# dense 1: Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# dense 2: Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(256,activation=\"softmax\"))\n",
    "\n",
    "opt = Adam(lr = 0.0001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d633d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_batches,\n",
    "          steps_per_epoch=len(train_batches),\n",
    "          validation_data=validation_batches,\n",
    "          validation_steps=len(validation_batches),\n",
    "          epochs=20,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1358b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82c380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbe8dc43",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode 1\n",
    "model.save_weights('face_Frontal-V2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd514a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode 2\n",
    "model.save_weights('Models/face_Frontal-V1_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141819c",
   "metadata": {},
   "source": [
    "# Plotting Accuracy & Loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81b1be84",
   "metadata": {},
   "source": [
    "#Tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f88a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a27e7dc3",
   "metadata": {},
   "source": [
    "# Curbe Erste Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca687b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "825c5bbb",
   "metadata": {},
   "source": [
    "#Curbe Zweite Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb5778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
